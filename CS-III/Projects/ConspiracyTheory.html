<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Dylan's Digital Portfolio</title>
    <meta charset="UTF-8">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Silkscreen&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans&family=Silkscreen&display=swap" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="apa2.css">
  </head>

  <body>
    <header>
      <h1>Dylan Pettijohn's Digital Portfolio</h1>
      <h2>Student at Allen High School</h2>
      <a class="headerLink" href="../../index.html">About Me</a>
      <a class="headerLink" href="../education.html">Education and Projects</a>
      <a class="headerLink" href="../articles.html">Articles</a>
      <a class="headerLink" href="./../Projects/ISP/isp.html">ISP</a>   
    </header>

    <h3><u>Advanced Sorts</u></h3>

    <p class="APAHead">Dylan Pettijohn<br>Allen High School<br>Computer Science II<br>Mr. Ben-Yaakov<br>September 9, 2022</p><br>

    <h4>The Basics of Recommendation Algorithms</h4> 

<p>Recommendation algorithms are software systems that curate content and generate personalized suggestions for users. Its goal is to find the best suited content, both in the form of user-generated content as well as advertisements. There are many types of recommendation algorithms, with collaborative filtering and content-based filtering being among the most prominent and popular. These algorithms implement user-based filtering, which suggests items based on similar users' preferences. As well as item-based filtering which suggests items similar to a user's previous interactions. All these algorithms are built on an interaction and retention tracking system that figures out what a user likes based on how long they spend on a piece of content, whether or not they like it, if they comment on it, and if they share it to others. These algorithms are implemented throughout the service to maximize the amount of data collected. This is done to hone the algorithm’s accuracy and create more precise recommendations and user preference profiles (this can also be achieved through the recommendation algorithm being cross-platform, for example, Google Adsense operating across all Google platforms like YouTube as well as other independent webpages). </p>

<h4>The Feedback Loop: Explained</h4>

<p>The Feedback Loop is a natural consequence of human behavior, these algorithms are designed to maximize retention and user satisfaction. Humans do not like having their ideas challenged or being faced with opposing opinions. This can be observed throughout traditional media where news outlets will split themselves along party lines, decreasing the opposition and allowing for viewers to bolster their own beliefs without being challenged by opposing ones (the same can be said for cable news and radio). The feedback loop can be seen throughout all platforms, news media, and every everyday interpersonal interactions. Users tend to gravitate towards things that echo their beliefs. As a user spends time on any platform, they feel more comfortable watching content that reinforces their own worldview and therefore the recommendation algorithm will notice and recommend more similar or even more extreme viewpoints. Eventually, the recommendation algorithm may stop recommending opposing views altogether creating an “echo chamber” . An echo chamber is created when the members of a niche group sub-consciously or intentionally radicalize each other. And since they’re no longer being exposed to opposing views that push against the narrative of the echo chamber their views will slowly become more radical and homogenous with the group. This process of digital community isolation and self-radicalization can lead to real-life extremist violence, such as the Allen outlet mall shooter, school shooters, incels, racists, homophobes, anti-semites, etc. </p>

<h4>Conspiracy Theories and Algorithmic Amplification</h4> 
<p>Recommendation algorithms also have the power to promote and propagate conspiracy theories throughout online communities. as the algorithms are designed to provide individuals with the exact content they want (using the methods previously described). Therefore, the algorithms have the unintended consequence of finding people who are more vulnerable to believe conspiracy theories and exposing them to the false content, such as the anti-vaccination movement and the idea of heavy metals in vaccines or vaccines causing autism. These conspiracy theories are often packaged with a sensationalist hook in the form of a video title or article headline, designed to create as many interactions as possible in order to play into the recommendation algorithm’s interaction/retention tracking system. This system combined with the feedback loop, creates an environment where sensationalist far-fetched ideas are propagated and rarely challenged within the spaces that actually believe them. Although the average person doesn’t believe in a flat-earth and regularly sees proof of a round earth; flat-earthers will be less likely to see that same proof and evidence, because the algorithm recognizes it as something they probably won’t like.</p>

<h4>Platform Incentives, Hint: it’s money</h4>

<p>Platforms will incentivize the creation of sensationalist content with the hope of increasing both retention and user interaction. They do this, because it creates an engaging, whether that engagement is positive or negative, space that keeps users active in order to show ads and profit off their users. This is because, for systems like Youtube and Meta, the longer you stay on the platform, the more advertisements can be served to you, therefore the more money the company and creators make. In addition, the more users that interact with content, the more the platform is able to charge for advertisement space, thus driving up profits. These platforms are designed to make as much money as possible, so it makes sense that their algorithms view profit as the top priority. However, an unintended consequence of this seems to be the promotion of poorly fact-checked and often inappropriate paid content. As creators figure out the type of content that the algorithm promotes, many begin producing content designed specifically with the algorithm favored content traits in mind in order to gain popularity and a following on the platform. Which in turns incentivizes clickbaity and poorly researched sensationalist content. </p>

<h4>Potential for Exploitation</h4> 

<p>The potential for exploitation of recommendation algorithms comes from bad-faith actors who are aware of the previously discussed weaknesses and features of common algorithms. They exploit the software to enrich themselves and/or propagate their own ideology. As discussed before, platforms will often create recommendation algorithms that demand retention and interaction in order for content to be pushed to many users, and oftentimes the content that is the most successful in terms of interactions and retention is also the most polarizing. Due to this, polarizing content will be pushed to people who the algorithm knows are most likely to be receptive and engaged. Bad-faith actors often work for money offered by the platform in exchange for creating engaging content, to propagate their own ideology (regardless of how detached from reality their ideology is), sell a product, or simply to have a larger number on their profile and experience the modern day  fame provided by social media platforms. </p>


  </body>
  </html>
